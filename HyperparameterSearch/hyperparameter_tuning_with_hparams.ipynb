{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TsHV-7cpVkyK"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "atWM-s8yVnfX"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file was heavily changed by Nico Jahn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code starts here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8p3Tbx8cWEFA"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lEWCCQYkWIdA"
   },
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mVtYvbbIWRkV"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "z8b82G7YksOS",
    "outputId": "8d018f2d-7574-4af2-b8cb-0452f8d54724"
   },
   "outputs": [],
   "source": [
    "# get all data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# split data and normalize the input data in a range between 0 and 1\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# convert labels from sparse to one hot encoded vectors\n",
    "y_train = tf.one_hot(y_train,10)\n",
    "y_test = tf.one_hot(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Euw0agpWb4V"
   },
   "outputs": [],
   "source": [
    "# define hyperparameter to search for\n",
    "HP_LR = hp.HParam('Learning Rate', hp.IntInterval(-3,-2)) # is later used as log10 power\n",
    "HP_EPOCHS = hp.HParam('Number of Epochs', hp.Discrete([1,3,5])) # separate models are evaluated after n epochs\n",
    "\n",
    "# collect all hyperparameter\n",
    "hparams = [HP_EPOCHS,HP_LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Euw0agpWb4V"
   },
   "outputs": [],
   "source": [
    "# define metrics for evaluation\n",
    "METRIC_CCE = 'categorical crossentropy'\n",
    "METRIC_RECALL = 'recall'\n",
    "METRIC_PRECISION = 'precision'\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Precision_and_recall#Imbalanced_data\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "METRIC_BALANCED_ACCURACY = 'balanced accuracy'\n",
    "METRIC_F1 = 'f1 score'\n",
    "#METRIC_PPCR = 'predicted positive condition rate'\n",
    "\n",
    "# collect all metrics\n",
    "metrics = [hp.Metric(METRIC_CCE, display_name='Crossentropy'), \\\n",
    "                    hp.Metric(METRIC_RECALL, display_name='Recall'), \\\n",
    "                    hp.Metric(METRIC_PRECISION, display_name='Precision'), \\\n",
    "                    hp.Metric(METRIC_ACCURACY, display_name='Accuracy'), \\\n",
    "                    hp.Metric(METRIC_BALANCED_ACCURACY, display_name='Balanced Accuracy'), \\\n",
    "                    hp.Metric(METRIC_F1, display_name='F1 Score'), \\\n",
    "                    #hp.Metric(METRIC_PPCR, display_name='PPCR'), \\\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Euw0agpWb4V"
   },
   "outputs": [],
   "source": [
    "# create a default file writer\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(hparams=hparams,metrics=metrics,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hG-zalNfW5Zl"
   },
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "    # load your hyperparameter from the dict\n",
    "    learning_rate = hparams[HP_LR]\n",
    "    num_epochs = hparams[HP_EPOCHS]\n",
    "    \n",
    "    # creating the model\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(10, activation=tf.nn.softmax),\n",
    "    ])\n",
    "    \n",
    "    # compile/define optimizer and metrics\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "    model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=[   tf.keras.metrics.CategoricalCrossentropy(name='cce'), \\\n",
    "                        tf.keras.metrics.Recall(name='recall'), \\\n",
    "                        tf.keras.metrics.Precision(name='precision'), \\\n",
    "                        tf.keras.metrics.TruePositives(name='tp'), \\\n",
    "                        tf.keras.metrics.TrueNegatives(name='tn'), \\\n",
    "                        tf.keras.metrics.FalsePositives(name='fp'), \\\n",
    "                        tf.keras.metrics.FalseNegatives(name='fn')],\n",
    "    )\n",
    "    \n",
    "    # train and evaluate on metrics\n",
    "    model.fit(x_train, y_train, epochs=num_epochs)\n",
    "    loss, cce, recall, precision, tp, tn, fp, fn = model.evaluate(x_test, y_test)\n",
    "    \n",
    "    # return necessary metrics\n",
    "    return cce, recall, precision, tp, tn, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8j-fO6nEXRfW"
   },
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        step = hparams[HP_EPOCHS]\n",
    "        \n",
    "        # do the training procedure once\n",
    "        # TODO: create n repetitions to create a mean value or do n-folds\n",
    "        cce, recall, precision, tp, tn, fp, fn = train_test_model(hparams)\n",
    "        \n",
    "        # basic metrics which are precomputed for us\n",
    "        tf.summary.scalar(METRIC_CCE, cce, step=step)\n",
    "        tf.summary.scalar(METRIC_RECALL, recall, step=step)\n",
    "        tf.summary.scalar(METRIC_PRECISION, precision, step=step)\n",
    "        \n",
    "        # more advanced metrics which we have to compute ourselves\n",
    "        ## Accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, (tp+tn)/(tp+tn+fp+fn), step=step)\n",
    "        ## Balanced accuracy = (TPR+TNR)/2\n",
    "        tf.summary.scalar(METRIC_BALANCED_ACCURACY, ((tp/(tp+fn))+(tn/(tn+fp)))/2, step=step)\n",
    "        ## Predicted positive condition rate = (tp+fp)(tp+fp+tn+fn)\n",
    "        #tf.summary.scalar(METRIC_PPCR, (tp+fp)/(tp+tn+fp+fn), step=step)\n",
    "        ## F1 = 2* (precision*recall)/(precision+recall)\n",
    "        tf.summary.scalar(METRIC_F1, 2*(precision*recall)/(precision+recall), step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "colab_type": "code",
    "id": "KbqT5n-AXd0h",
    "outputId": "f906b680-f941-4c7c-9b15-4dcc760bf2bb",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'Number of Epochs': 1, 'Learning Rate': 0.001}\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.4605 - cce: 0.4605 - recall: 0.8035 - precision: 0.9265 - tp: 48210.0000 - tn: 536173.0000 - fp: 3827.0000 - fn: 11790.0000\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2186 - cce: 0.2186 - recall: 0.9219 - precision: 0.9526 - tp: 9219.0000 - tn: 89541.0000 - fp: 459.0000 - fn: 781.0000\n",
      "\n",
      "--- Starting trial: run-1\n",
      "{'Number of Epochs': 1, 'Learning Rate': 0.01}\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.4262 - cce: 0.4262 - recall: 0.8345 - precision: 0.9025 - tp: 50069.0000 - tn: 534589.0000 - fp: 5411.0000 - fn: 9931.0000\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2186 - cce: 0.2186 - recall: 0.9292 - precision: 0.9458 - tp: 9292.0000 - tn: 89468.0000 - fp: 532.0000 - fn: 708.0000\n",
      "\n",
      "--- Starting trial: run-2\n",
      "{'Number of Epochs': 3, 'Learning Rate': 0.001}\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.4780 - cce: 0.4780 - recall: 0.7955 - precision: 0.9218 - tp: 47731.0000 - tn: 535952.0000 - fp: 4048.0000 - fn: 12269.0000\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2770 - cce: 0.2770 - recall: 0.8991 - precision: 0.9394 - tp: 53944.0000 - tn: 536520.0000 - fp: 3480.0000 - fn: 6056.0000\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2387 - cce: 0.2387 - recall: 0.9128 - precision: 0.9446 - tp: 54767.0000 - tn: 536788.0000 - fp: 3212.0000 - fn: 5233.0000\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1552 - cce: 0.1552 - recall: 0.9471 - precision: 0.9635 - tp: 9471.0000 - tn: 89641.0000 - fp: 359.0000 - fn: 529.0000\n",
      "\n",
      "--- Starting trial: run-3\n",
      "{'Number of Epochs': 3, 'Learning Rate': 0.01}\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.4044 - cce: 0.4044 - recall: 0.8472 - precision: 0.9080 - tp: 50831.0000 - tn: 534848.0000 - fp: 5152.0000 - fn: 9169.0000\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3247 - cce: 0.3247 - recall: 0.8846 - precision: 0.9218 - tp: 53076.0000 - tn: 535500.0000 - fp: 4500.0000 - fn: 6924.0000\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2949 - cce: 0.2949 - recall: 0.8961 - precision: 0.9281 - tp: 53765.0000 - tn: 535835.0000 - fp: 4165.0000 - fn: 6235.0000\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2057 - cce: 0.2057 - recall: 0.9341 - precision: 0.9527 - tp: 9341.0000 - tn: 89536.0000 - fp: 464.0000 - fn: 659.0000\n",
      "\n",
      "--- Starting trial: run-4\n",
      "{'Number of Epochs': 5, 'Learning Rate': 0.001}\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.4693 - cce: 0.4693 - recall: 0.7999 - precision: 0.9237 - tp: 47995.0000 - tn: 536037.0000 - fp: 3963.0000 - fn: 12005.0000\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2793 - cce: 0.2793 - recall: 0.8976 - precision: 0.9390 - tp: 53858.0000 - tn: 536504.0000 - fp: 3496.0000 - fn: 6142.0000\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2402 - cce: 0.2402 - recall: 0.9142 - precision: 0.9443 - tp: 54854.0000 - tn: 536767.0000 - fp: 3233.0000 - fn: 5146.0000\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2155 - cce: 0.2155 - recall: 0.9237 - precision: 0.9495 - tp: 55420.0000 - tn: 537055.0000 - fp: 2945.0000 - fn: 4580.0000\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2045 - cce: 0.2045 - recall: 0.9278 - precision: 0.9512 - tp: 55668.0000 - tn: 537145.0000 - fp: 2855.0000 - fn: 4332.0000\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1436 - cce: 0.1436 - recall: 0.9533 - precision: 0.9640 - tp: 9533.0000 - tn: 89644.0000 - fp: 356.0000 - fn: 467.0000\n",
      "\n",
      "--- Starting trial: run-5\n",
      "{'Number of Epochs': 5, 'Learning Rate': 0.01}\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.4405 - cce: 0.4405 - recall: 0.8327 - precision: 0.9002 - tp: 49964.0000 - tn: 534462.0000 - fp: 5538.0000 - fn: 10036.0000\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3500 - cce: 0.3500 - recall: 0.8732 - precision: 0.9157 - tp: 52390.0000 - tn: 535177.0000 - fp: 4823.0000 - fn: 7610.0000\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3252 - cce: 0.3252 - recall: 0.8850 - precision: 0.9221 - tp: 53103.0000 - tn: 535515.0000 - fp: 4485.0000 - fn: 6897.0000\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3054 - cce: 0.3054 - recall: 0.8932 - precision: 0.9274 - tp: 53594.0000 - tn: 535806.0000 - fp: 4194.0000 - fn: 6406.0000\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3022 - cce: 0.3022 - recall: 0.8949 - precision: 0.9276 - tp: 53697.0000 - tn: 535812.0000 - fp: 4188.0000 - fn: 6303.0000\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1796 - cce: 0.1796 - recall: 0.9466 - precision: 0.9608 - tp: 9466.0000 - tn: 89614.0000 - fp: 386.0000 - fn: 534.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for epochs in HP_EPOCHS.domain.values:\n",
    "    min_, max_= HP_LR.domain.min_value, HP_LR.domain.max_value\n",
    "    for lr in np.logspace(min_,max_,max_-min_+1):\n",
    "        # write your hyperparameter to the dict\n",
    "        hparams = {\n",
    "                HP_EPOCHS: epochs,\n",
    "                HP_LR: lr,\n",
    "        }\n",
    "        \n",
    "        # 1 hp combination test\n",
    "        run_name = \"run-%d\" % session_num\n",
    "        print('--- Starting trial: %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run('logs/hparam_tuning/' + run_name, hparams)\n",
    "        print()\n",
    "        session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard 2.2.1 started at http://b86465c257f6:6006/\n",
      "PID = 5693; use 'kill 5693' to quit\n",
      "\n",
      "Shutting down\n"
     ]
    }
   ],
   "source": [
    "# Copied from: https://github.com/tensorflow/tensorboard/issues/3032#issuecomment-566140412\n",
    "# NOTE: When starting Tensorboard via magic command, then i can't kill it properly in a container\n",
    "# Therefore, couple it with the kernel and just restart the kernel later on\n",
    "# This is a continous while loop, so this will stop code execution after it \n",
    "import tensorboard\n",
    "import os\n",
    "import time\n",
    "\n",
    "tb = tensorboard.program.TensorBoard()\n",
    "tb.configure(bind_all=True, logdir=\"logs/\", port=6006)\n",
    "url = tb.launch()\n",
    "print(\"TensorBoard %s started at %s\" % (tensorboard.__version__, url))\n",
    "pid = os.getpid()\n",
    "print(\"PID = %d; use 'kill %d' to quit\" % (pid, pid))\n",
    "while True:\n",
    "    try:\n",
    "        time.sleep(60)\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "print()\n",
    "print(\"Shutting down\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hyperparameter_tuning_with_hparams.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
